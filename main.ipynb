{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profiling.context_manager.spark_context_manager import SparkContextManager\n",
    "from profiling.importer.importer import Importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_manager = SparkContextManager()\n",
    "spark = spark_manager.get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "importer = Importer(SparkSession=spark)\n",
    "profiling_df = importer.import_csv_table(file_path='./data/data_paper_sample_10k.csv', header='True', inferschema='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'profiling.config.table_profiler_config' from '/Users/erfankashani/code/src/github.com/erfan_github/data_profiler/profiling/config/table_profiler_config.py'>\n"
     ]
    }
   ],
   "source": [
    "from profiling.config import table_profiler_config\n",
    "\n",
    "print(table_profiler_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.01905\n"
     ]
    }
   ],
   "source": [
    "estimated_df = profiling_df.sample(fraction = 0.5)\n",
    "estimated_df.cache().foreach(lambda x: x)\n",
    "catalyst_plan = estimated_df._jdf.queryExecution().logical()\n",
    "test_kb = spark._jsparkSession.sessionState().executePlan(catalyst_plan).optimizedPlan().stats().sizeInBytes()\n",
    "print(test_kb * 50 / (1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'id',\n",
       " 'authors',\n",
       " 'title',\n",
       " 'year',\n",
       " 'n_citation',\n",
       " 'page_start',\n",
       " 'page_end',\n",
       " 'doc_type',\n",
       " 'publisher',\n",
       " 'volume',\n",
       " 'issue',\n",
       " 'doi',\n",
       " 'references',\n",
       " 'fos',\n",
       " 'venue',\n",
       " 'indexed_abstract']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col[0] for col in profiling_df.dtypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profiling.profiler.table_profiler import TableProfiler\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, BooleanType, DateType, LongType\n",
    "\n",
    "spark = SparkSession.builder.appName('TestSparkSession').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "input_data = [(1,500,200.0, 'Tesla',True,datetime.strptime('2019-12-01','%Y-%m-%d')),\n",
    "                (2,0,200.0, 'Microsoft',True,datetime.strptime('2019-12-02','%Y-%m-%d')),\n",
    "                (3,0,0.0, 'Google',False,datetime.strptime('2019-12-03','%Y-%m-%d')),\n",
    "                (4,1000,0.0, 'Apple',True,datetime.strptime('2019-12-04','%Y-%m-%d')),\n",
    "                (5,None,34.0, 'Costco',True,datetime.strptime('2019-12-05','%Y-%m-%d')),\n",
    "                (6,None,None, 'Walmart',False,datetime.strptime('2019-12-06','%Y-%m-%d')),\n",
    "                (7,34,None, 'Target',True,datetime.strptime('2019-12-07','%Y-%m-%d')),\n",
    "                (8,10,20.0, 'Home Depot',True,datetime.strptime('2019-12-08','%Y-%m-%d'))\n",
    "                ]\n",
    "\n",
    "expected_data = [(8, 6, 3, 2, 1)]\n",
    "\n",
    "input_schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('revenue', LongType(), True),\n",
    "    StructField('budget', FloatType(), True),\n",
    "    StructField('company_name', StringType(), True),\n",
    "    StructField('is_active', BooleanType(), True),\n",
    "    StructField('report_date', DateType(), True),\n",
    "])\n",
    "expected_schema = StructType([\n",
    "        StructField('record_count', IntegerType(), True),\n",
    "        StructField('column_count', IntegerType(), True),\n",
    "        StructField('numeric_column_count', IntegerType(), True),\n",
    "        StructField('categorical_column_count', IntegerType(), True),\n",
    "        StructField('date_column_count', IntegerType(), True),\n",
    "    ])\n",
    "\n",
    "input_df = spark.createDataFrame(data=spark.sparkContext.parallelize(input_data), schema=input_schema)\n",
    "expected_df = spark.createDataFrame(data=spark.sparkContext.parallelize(expected_data), schema=expected_schema)\n",
    "table_profiler = TableProfiler(spark, input_df)\n",
    "output_df = table_profiler.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+--------------------+------------------------+-----------------+\n",
      "|record_count|column_count|numeric_column_count|categorical_column_count|date_column_count|\n",
      "+------------+------------+--------------------+------------------------+-----------------+\n",
      "|           8|           6|                   2|                       2|                1|\n",
      "+------------+------------+--------------------+------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert output_df.schema == expected_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('revenue', 'bigint'),\n",
       " ('budget', 'float'),\n",
       " ('company_name', 'string'),\n",
       " ('is_active', 'boolean'),\n",
       " ('report_date', 'date')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3 (default, Jul  2 2020, 11:26:31) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e94ce9fc9800555c736dc8fe0d64f94f27749329f68471085d2002df28c6a113"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
